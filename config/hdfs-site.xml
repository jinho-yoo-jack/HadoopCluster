<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
    <!-- NameNode Config -->
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///data/hdfs/namenode</value>
        <description>NameNode directory for namespace and transaction logs storage.</description>
    </property>
    <property>
        <name>dfs.namenode.handler.count</name>
        <value>10</value>
    </property>
    <property>
        <!-- 네임서비스 리스트. 콤마(,)로 구분하여 여러개 설정가능.
        HDFS Federation 등을 위한 부분인데, 일단 core-site.xml에서 fs.defaultFS로 지정한 이름 하나만 지정함.-->
        <name>dfs.nameservices</name>
        <value>kcp-hadoop-cluster</value>
    </property>
    <property>
        <name>dfs.ha.namenodes.kcp-hadoop-cluster</name>
        <value>kcp-nn-1,kcp-nn-2</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.kcp-hadoop-cluster.kcp-nn-1</name>
        <value>kcp-nn-1:18020</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.kcp-hadoop-cluster.kcp-nn-2</name>
        <value>kcp-nn-2:18020</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.kcp-hadoop-cluster.kcp-nn-1</name>
        <value>kcp-nn-1:50071</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.kcp-hadoop-cluster.kcp-nn-2</name>
        <value>kcp-nn-2:50071</value>
    </property>
    <!-- DataNode Config -->
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:///data/hdfs/datanode1,file:///data/hdfs/datanode2,file:///data/hdfs/datanode3</value>
        <description>DataNode directory</description>
    </property>
    <property>
        <name>dfs.datanode.handler.count</name>
        <value>10</value>
        <description>The number of server threads for the datanode.</description>
    </property>
    <property>
        <name>dfs.datanode.http-address</name>
        <value>0.0.0.0:50072</value>
    </property>
    <!-- About default Data process -->
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
    <!-- HA Config -->
    <!-- JournalNode Config -->
    <property>
        <name>dfs.journalnode.edits.dir</name>
        <value>/data/hdfs/journalnode</value>
    </property>
    <!--NFS(Network FS) Config -->
    <property>
        <!-- NameNode가 EditLog를 쓰고 읽을 JournalNode URI -->
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://kcp-nn-1:18485;kcp-nn-2:18485;kcp-dn-1:18485/hadoop-cluster</value>
    </property>
    <property>
        <!-- HDFS 클라이언트가 active NameNode 접근 시, 사용되는 Java class -->
        <name>dfs.client.failover.proxy.provider.kcp-hadoop-cluster</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <property>
        <!-- Failover 상황에서 기존 active NameNode 차단 시, 사용할 방법 지정 -->
        <name>dfs.ha.fencing.methods</name>
        <value>shell(/bin/true)</value>
    </property>
    <property>
        <!-- Automatic failover configuration -->
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
    </property>
</configuration>
